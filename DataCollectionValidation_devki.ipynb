{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416e2e55-57e9-47e4-8e05-9171e0954b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/patel.devki1/Dataset\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "137ab2be-4584-466f-b07a-1e4ca9d92c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directory where the images are stored\n",
    "directory = '/home/patel.devki1/Dataset/lung_image_sets/lung_n/lung_n_'\n",
    "\n",
    "# Regex pattern to match files like 'lungn1.jpeg'\n",
    "pattern = re.compile(r'lungn(\\d+)\\.jpeg')\n",
    "\n",
    "# List all files in the directory and filter using the regex pattern\n",
    "files = os.listdir(directory)\n",
    "lungn_files = [f for f in files if pattern.match(f)]\n",
    "\n",
    "# Count the number of images\n",
    "total_images = len(lungn_files)\n",
    "print(\"Total number of images:\", total_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb57036-7927-4db2-9f2d-c77d121f5e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing files found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory where the images are stored\n",
    "directory = '/home/patel.devki1/Dataset/lung_image_sets/lung_n/lung_n_'\n",
    "\n",
    "# Get all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Extract the numerical part from each file name and convert it to integers\n",
    "actual_numbers = [int(file.split('.')[0].split('lungn')[-1]) for file in files if file.startswith('lungn')]\n",
    "\n",
    "# Generate a list of expected numerical file names based on the range of numbers in the actual files\n",
    "expected_numbers = list(range(min(actual_numbers), max(actual_numbers) + 1))\n",
    "\n",
    "# Find the missing file numbers by subtracting the actual numbers from the expected numbers\n",
    "missing_numbers = set(expected_numbers) - set(actual_numbers)\n",
    "\n",
    "# Print the missing file numbers\n",
    "if missing_numbers:\n",
    "    print(\"Missing files:\")\n",
    "    for num in missing_numbers:\n",
    "        print(f\"lungn{num}.jpeg\")\n",
    "else:\n",
    "    print(\"No missing files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f196a149-2f10-425f-a395-d306164e4307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directory where the images are stored\n",
    "directory = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc'\n",
    "\n",
    "# Regex pattern to match files like 'lungn1.jpeg'\n",
    "pattern = re.compile(r'lungscc(\\d+)\\.jpeg')\n",
    "\n",
    "# List all files in the directory and filter using the regex pattern\n",
    "files = os.listdir(directory)\n",
    "lungscc_files = [f for f in files if pattern.match(f)]\n",
    "\n",
    "# Count the number of images\n",
    "total_images = len(lungscc_files)\n",
    "print(\"Total number of images:\", total_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93541e3-3e53-4656-bcb4-95848e3683a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing files found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory where the images are stored\n",
    "directory = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc/lung_scc_'\n",
    "\n",
    "# Get all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Extract the numerical part from each file name and convert it to integers\n",
    "actual_numbers = [int(file.split('.')[0].split('lungscc')[-1]) for file in files if file.startswith('lungscc')]\n",
    "\n",
    "# Generate a list of expected numerical file names based on the range of numbers in the actual files\n",
    "expected_numbers = list(range(min(actual_numbers), max(actual_numbers) + 1))\n",
    "\n",
    "# Find the missing file numbers by subtracting the actual numbers from the expected numbers\n",
    "missing_numbers = set(expected_numbers) - set(actual_numbers)\n",
    "\n",
    "# Print the missing file numbers\n",
    "if missing_numbers:\n",
    "    print(\"Missing files:\")\n",
    "    for num in missing_numbers:\n",
    "        print(f\"lungscc{num}.jpeg\")\n",
    "else:\n",
    "    print(\"No missing files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9410821f-83c6-48d2-99d6-a8b5fa79401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/patel.devki1/.local/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /home/patel.devki1/.local/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: jinja2 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/patel.devki1/.local/lib/python3.8/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/patel.devki1/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: numpy in /home/patel.devki1/.local/lib/python3.8/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc148b3-c52d-4693-98d4-900cd18679f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the path to your original dataset directory\n",
    "original_data_dir = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc/lung_scc_'\n",
    "\n",
    "# Define paths for train and test directories\n",
    "# train_dir = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc/train_data/'\n",
    "# test_dir = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc/test_data/'\n",
    "\n",
    "train_dir = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc/lung_scc_train_data'\n",
    "test_dir = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc/lung_scc_test_data'\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Get the list of all files in the original dataset directory\n",
    "all_files = os.listdir(original_data_dir)\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Move files to train directory\n",
    "for file in train_files:\n",
    "    src = os.path.join(original_data_dir, file)\n",
    "    dst = os.path.join(train_dir, file)\n",
    "    if os.path.isdir(src):\n",
    "        if not os.path.exists(dst):  # Check if destination directory already exists\n",
    "            shutil.copytree(src, dst)  # Copy entire directory and its contents\n",
    "    else:\n",
    "        if not os.path.exists(dst):  # Check if file already exists in destination\n",
    "            shutil.copyfile(src, dst)  # Copy individual file if it doesn't exist\n",
    "\n",
    "# Move files to test directory\n",
    "for file in test_files:\n",
    "    src = os.path.join(original_data_dir, file)\n",
    "    dst = os.path.join(test_dir, file)\n",
    "    if os.path.isdir(src):\n",
    "        if not os.path.exists(dst):  # Check if destination directory already exists\n",
    "            shutil.copytree(src, dst)  # Copy entire directory and its contents\n",
    "    else:\n",
    "        if not os.path.exists(dst):  # Check if file already exists in destination\n",
    "            shutil.copyfile(src, dst)  # Copy individual file if it doesn't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9b51ce8-62c6-4df5-91dd-c835faea74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "train_data_new = os.path.join(train_dir, 'train')\n",
    "test_data_new = os.path.join(test_dir, 'test')\n",
    "\n",
    "# Create datasets from folders\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d87aefe-1fdb-4abc-8e40-9b64b8908a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "class LungNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(LungNet, self).__init__()\n",
    "        # Define your model architecture here\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LungNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fd440b-6f36-4976-aee9-f2c18d1c8a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is readable: True\n",
      "Folder is writable: True\n",
      "Folder is executable: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the folder you want to check permissions for\n",
    "directory = '/home/patel.devki1/Dataset/lung_image_sets/lung_scc'\n",
    "\n",
    "folder_path = directory\n",
    "\n",
    "# Use the os.access() function to check permissions\n",
    "readable = os.access(folder_path, os.R_OK)\n",
    "writable = os.access(folder_path, os.W_OK)\n",
    "executable = os.access(folder_path, os.X_OK)\n",
    "\n",
    "# Print the permissions status\n",
    "print(f'Folder is readable: {readable}')\n",
    "print(f'Folder is writable: {writable}')\n",
    "print(f'Folder is executable: {executable}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ba944-1ec4-4e87-8948-dd0a2c47f983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81ea7c24-c10b-4e2a-a745-2a6aae1411e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.2.2\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/patel.devki1/.local/lib/python3.8/site-packages\n",
      "Requires: networkx, fsspec, nvidia-cublas-cu12, nvidia-cudnn-cu12, nvidia-curand-cu12, sympy, nvidia-nccl-cu12, nvidia-cufft-cu12, nvidia-cuda-nvrtc-cu12, nvidia-nvtx-cu12, filelock, nvidia-cusparse-cu12, triton, nvidia-cuda-runtime-cu12, nvidia-cuda-cupti-cu12, jinja2, typing-extensions, nvidia-cusolver-cu12\n",
      "Required-by: torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6be1e1b7-11e1-4478-be2b-83789adc9ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torchvision\n",
      "Version: 0.17.2\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: /home/patel.devki1/.local/lib/python3.8/site-packages\n",
      "Requires: torch, numpy, pillow\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1beb2a-1a2f-45c2-91f1-2d93611a40b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
